Trabajo adelantado\En esta sección son descritosson e decriben los avances realizadosa y+ el estado act. Está separada en dos subsecciones: la primera trata sobre la obtención de los datos necesarios y la segunda sobre el trabajo previo que dadel aualas visualizaciones que diellan en este proyecto.ron origen a las ideas qSiguiendo el programa descrito en Metodología se ha realizado un “crowd sourcing” de datos y se ha estudiado su forma de descargala manera destn investigado las alternativas para descargarlos. ue se desarror  desarrolladas hasta ahora \u000bqu de la FCFM de U-Cursosele dieron desarrolladas hasta ahora  adneción de los datsbtenrse encarga ual del proyecto n n dse e tsa eu000b\Siguiendo el programa descrito en Metodologí, más algunos de estudiantes de otras facultadesa se ha realizado un 60 “c50 rowhans sido reidod s hasta ahora. De éstos serán seleccionados los que cumplan las siguientes características: (1) el documento debe tener un cierto mínimo de complejidad sintáctica (estar estructurado cturaconfoquinientas palabras (una8areas r)mmás que en li \EPara descargar el historial puede ser descargado usando el API REST de Google Docs, entregándole el ID del documento y los números de las revisiones que se quieren extraer. Esto implica que no se puede pedir simplemente toda la historia del documento, sin saber cuántas revisiones esta contiene, pero esta información puede ser conocida, hasta donde mejor sabemos, teniendo instalada la extensión de Chrome Draftback [], la cual, entre otras cosas, nos revela el número de la última revisión de un documento. Al solicitar las revisiones éstas llegan en formato Json, cada una con timestamp, usuario asociado, y el delta de texto (que ronda entre uno y dos caracteres por cambio, es decir, diferencias de tiempo menores a un segundo), además de otra información asociada a los cambios de formato (metatexto), de la cual obviamente debemos despojarnos.que obviamente debe s\En un trabajo realizado previamente por el autor, fue estudiado vel proceso deescritura de un libro particular, del cual se tenía acceso a un historial de más de 15 revisiones. El libro corresponde a un texto de literatura u científaico en inglés ya publicado de cerca alrededor de Usando los datos estos datos, se generaron dos visualizaciones que mostraron una marcada estructura de fases en a lo largo de las revisiones y dieron evidencias de que éste llevaba hacia un mayor orden de las ideas.\Primero se apuntó a construir un gráfico de líneas que mostrara la evolución de la densidad de ciertas palabras clave a través de la historia del libro. El procesamiento de los libros (stemming, tabulación) se hizo en Processing, del cual se exportaron los datos para ser usados en JavaScript con la librería D3Plus.\La Figura 1 muestra el gráfico resultante, el cual, visto desde un navegador, es interactivo y nos muestra al pasar el puntero sobre una línea qué concepto representa. Los estemas fueron seleccionados a mano de entre los más frecuentes y significativos para el libro final. El eje Y es la cantidad de apariciones de la idea dentro de una cantidad determinada de oraciones separadas por punto y el eje X el “tiempo” o la posición dentro de la historia de la obra.\u000b\nAunque la división entre una versión y otra no es explícita (de hecho, éstas fueron agregadas secuencialmente como si fueran un sólo texto) se puede observar que por el segundo cuarto de la dimensión en X las líneas empiezan a “pulsar” con cierta regulariadecuarses  aun ritmos ede dad, a respetarestimar un patrón cíclico, el cual nos permite ver de hecho dónde comienza y termina una nueva versión. Esta regularidad se alcanza desde lamás séptima (en realidad, decimosexta) versión, que es cuando su estructura queda ya más bien definida y no sufre grandes expansiones en contenido de ese punto en adelante. Al principio, en el primer cuarto del gráfico que, podemos calcular, reúne 7 versiones (las primeras 6 bastante cortas), la densidad de ideas es caótica y no se nos permite adivinar una clara separación entre capítulos o versiones. Los picos de las curvas se sobrelapan y confunden. Incluso cuando el libro adquiere una unidad definida en la séptima versión, se sigue manteniendo la dinámica de incómoda promiscuidad entre ideas, pero a medida que nos vamos acercando a la final, los máximos locales de las curvas se van acomodando a una distancia razonable unos de otros, adquiriendo cada uno un espacio propio y bien delimitado. Esto se interpretó como la condensación de ideas que conlleva el proceso de escritura y reescritura de un texto de divulgación como el analizado, donde una adecuada estructura es aquella que resulta ordenada, clara y concisa para el lector, y donde cada idea importante, cuya resignificación es tarea de la obra, ocupa un lugar bien definido dentro del espacio temporal del\Luego, su000b texto.\nLas características mencionadas pueden ser, como efectivamente lo son, propias del libro estudiado en particular, pero sin duda deben ser compartidas por un porcentaje de obras de esta índole, dependiendo quizás, del autor o la intención de éste.\napariciones de la idea dentro de una cantidad determinada de oraciones separadas por punto y el eje X el “tiempo” o la posición dentro de la historia de la obra.\nAunque la división entre una versión y otra no es explícita (de hecho, éstas fueron agregadas secuencialmente como si fueran un sólo texto) se puede observar que por el segundo cuarto de la dimensión en X las líneas empiezan a “pulsar” con cierta regularidad, a respetar un patrón cíclico, el cual nos permite ver de hecho dónde comienza y termina una nueva versión. Esta regularidad se alcanza desde la séptima (en realidad, decimosexta) versión, que es cuando su estructura queda ya más bien definida y no sufre grandes expansiones en contenido de ese punto en adelante. Al principio, en el primer cuarto del gráfico que, podemos calcular, reúne 7 versiones (las primeras 6 bastante cortas), la densidad de ideas es caótica y no se nos permite adivinar una clara separación entre capítulos o versiones. Los picos de las curvas se sobrelapan y confunden. Incluso cuando el libro adquiere una unidad definida en la séptima versión, se sigue manteniendo la dinámica de incómoda promiscuidad entre ideas, pero a medida que nos vamos acercando a la final, los máximos locales de las curvas se van acomodando a una distancia razonable unos de otros, adquiriendo cada uno un espacio propio y bien delimitado. Esto se interpretó como la condensación de ideas que conlleva el proceso de escritura y reescritura de un texto de divulgación como el analizado, donde una adecuada estructura es aquella que resulta ordenada, clara y concisa para el lector, y donde cada idea importante, cuya resignificación es tarea de la obra, ocupa un lugar bien definido dentro del espacio temporal del texto.\nLas características mencionadas pueden ser, como efectivamente lo son, propias del libro estudiado en particular, pero sin duda deben ser compartidas por un porcentaje de obras de esta índole, dependiendo quizás, del autor o la intención de éste.\n\\u\u000b\u000b\u000b000b\u000bu000b
u000b\nPrimero se apuntó a construir un gráfico de líneas que mostrara la evolución de la densidad de ciertas palabras clave a través de la historia del libro. El procesamiento de los libros (stemming, tabulación) se hizo en Processing, del cual se exportaron los datos para ser usados en JavaScript con la librería D3Plus.\n\u0010\u0012\u001cFigura 1. Densidad de estemas clave en la historia agregada de Why Information Grows. Cada color representa un concepto: amarillo es “knowledge”; rojo es “information”; azul es “network”; verde oscuro es “embody”; marrón es “imagination”. Interpolación lineal fue usada sobre los puntos.\n \n\u0011La Figura 1 muestra el gráfico resultante, el cual, visto desde un navegador, es interactivo y nos muestra al pasar el puntero sobre una línea qué concepto representa. Los estemas fueron seleccionados a mano de entre los más frecuentes y significativos para el libro final. El eje Y es la cantidad de u000b\u000b
e evabel procespmarcadas estructrdieron luces sobre esclarecieron usuat2605000 páginas. rededor  a vie en un libro   \u000bSe ha estudiado ya el proceso d.\u000be a travésu000b
er filtradadespojada.del c és de otra ifoo con algo de informLas revisiones ed e c  u o puedeeno revisiones red s sel   l:. Tpuede pue de un documentoes  unu000bEste punto, el mining del historial, ha sido también un área de avance aunque no la más sencilla: según el actual conocimiento esparcido por Internet, no es posible descargar directamente las revisiones de un documento usando la API de Google Docs, sin embargo, se encontró una extensión de Chrome [1] que hace uso de esta información para, desde la misma página de edición de un documento de Google Docs, generar un “video” que permite hacer playback del changelog del texto. Este “video” puede ser extraído como \n
stas o tablas) y (2) el texto no debe superar las dos carillas en extensión, ya que por el momento el método de extracción del historial está imposibilitando la descarga de mayores volúmenes por dato. EÉste punto, el mining del historia, ha sido también un área de avance aunque no la más sencilla: según el actual conocimiento esparcido por Internet, no es posible descargar directamente las revisiones de un documento usando la API de Google Docs, sin embargo, se encontró una extensión de Chrome [1] que hace uso de esta información para, desde la misma página de edición de un documento de Google Docs, generarcrear un “vique permite hacerahcer deop de playbackllaybackvide Este “video” puede ser extraído como video  Lo qo” del chanSe diseñó e implementó realizó una visualpara texto versionado que permitía observar a grandes rasgos una estructura en el proceso de escritura. Se probó la visualización usando und ldibro de ensayo publicado, del cual
* se pudo conseguir un historial de 15 revisiones, que ibanm desde el primer bosquej*o hasta la versión final.oineieron consEl dato en el que se pEn ese momentoaización gelog del texto.
documento  ca render
ización on´no n documentoma CHromoe asocumeos e iha dado los resultados atdos q peor  vién l  de‘miningr es el siguiente punto .grdlitando mayores mo éstals eilas arno debe superar er m(  ado en párrafos sina cmdeben tener tengan la o. urcing” de  datos y se han investigado las alternativas para descargarlos  agr iahnse ha realizado un “crowd sourcing” de datos  sousourcefunding a , se han concentrado los esfuerzos en producir un De manera aún más resumida: cada columna en esta matriz es la bolsa de palabras de una oración y cada fila el un “tren de impuls (la señal) (ode una cierta palab, donde el orden de las filas está dado por el orden de la primera aparición de cada palabra. 
 La mat, que consta de unos donde hay presencia de apahayrece una palabra y ceros en todo elvisualizada luego de manera “directa”, con un  pixe de colorl blanco representando los ceros y u pixel negro los unos. En realidad, como la resolución no es suficiente en la mayoría de los casos para ver esta imagen dentro de una pantalla, se usa una interpolación lineal sobre los el valor final de los pixe\Aunque esta visualización es para texto versionado y no texto evolutivo, alcanza a capturar y sacar provecho del concepto de irreversibilidad. En la figura se ve cómo cambia el resultado cuando el orden de entrada de las revisiones es distintoLa ecapsólo u000b
les, lo que le da finalmente una textura en escala de gris. \u000be.\n pixeles antes de cdaopar Como Omo lns ñ \Este esquema puede aun aún ser mejorado en diferenpuntos: la granularidad con la que toma los datos es mucho menorgranularidad de visualización (debido a la limitante de la resolución de la imagen final)i, por lo que se podríahacer más eficiente y más expresivo si, por ejemplo, se tomase tomara como ventana de tiempo (columna) párrafos en vez de or, y se usase un locally weighted bag of words [17] para valorar los elementos de la matriz entre 0 ce1ro y uno.como7lowbowra  aciones.aytmoesi cent  a la rnel nivel al que toma .tes eser mejorado aún da para mejoras puede qÉsteu000b\\u000bn ou resto,donen una rceros donde0 riz es represena luego como una imagen como ua  ocmoo tadadxramla primrnra  s”  is‘,   xias En resumena base de datos sobre la cual trabajar posteriormente.\n, se han concentrado los esfuerzos e[1] https://chrome.google.com/webstore/detail/draftback/nnajoiemfpldioamchanognpjmocgkbg

n \u000b
producir una base de datos sobre la cual trabajar posteriormente.u000b
\tGeneración del dataset\Siguiendo el programa descrito en Metodología, se han co\tncentrado los esfuerzos en producir una base de datos sobre la cual trabajar posteriormente. Para este fin, se pidió a la comunidad estudiantil que compartieran con este proyecto sus propios documentos hechos con fines académicos en Google Docs. La respuesta de la comunida al proyecto fue afable, y aa l rpoeycd frente Alrededor de 80 enlaces fueron recibidos, los cuales deben pasar ahora por un proceso de selección basado en la complejidad sintáctica del contenido, lo que determinaría su utilidad para los experimentos a realizarse, en el que se espera que 20 pasen a formar parte del dataset definitivo.\Experimentos previosciP\La idea es similar a un espectrograma de frecuencias, sólo que cada frecuencia es un estema (la raíz algorítmicamente generada de una palabra) y el orden de los estemas en el eje Y está dado por su orden de aparición en el texto. El resultado es una matriz donde cada fila es un estema (o una ventana de estemas cuya primera aparición ocurrió de manera consecutiva) y cada columna una ventana de tiempo en el texto (una cierta cantidad de oraciones separadas por punto). El paso entre versiones se hace explícita en este caso por las líneas verticales.\nu000b
nu000bSiguiendo el programa descrito en Metodología, se han concentrado los esfuerzos en producir una base de datos sobre la cual trabajar posteriormente. Para este fin, se pidió a la comunidad estudiantil que compartieran con este proyecto sus propios documentos hechos con fines académicos en Google Docs. La respuesta de la comunidad frente Alrededor de 80 enlaces fueron recibidos, los cuales deben pasar ahora por un proceso de selección basado en la complejidad sintáctica del contenido, lo que determinaría su utilidad para los experimentos a realizarse, en el que se espera que 20 pasen a formar parte del dataset definitivo.\n
´nskjdfllkjdsflskdjfkjsdfñsldkf


\n\
t
\\u000bu000b



Ex

periencias previas

La idea es similar a un espectrograma de frecuencias, sólo que cada frecuencia es un estema (la raíz algorítmicamente generada de una palabra)  y el orden de los estemas en el eje Y está dado por su orden de aparicón en el textoión e n el tiempo. El resultado es una matriz donde cada fila es un estema (o una ventana de estemas cuya primera aparición ocurrió de manera consecutiva) y cada columna una ventana de tiempo en el texto (una cierta cantidad de oraciones separadas por punto). El paso entre versiones se hace explícita Generación del datasetObt
en este caso por las líneas verticales.\n

sanicas Siguiendo el programa descrito en Metodología, se han concentrado los esfuerzos en producirconseguir unadatos sobre la cual trabajar posteriormente. Para este fin, se pidió a la comunidad estudiantil que compartieran con este proyectoeenviaran sus propios documentos hechos con fines académicos en Go. La respuesta de la comunidad frente aAlrededor de 8060 enlaces fueron recibidos, los cuales  pasarán deben pasar ahora por un proceso de selección basado en la complejidad sintáctica del contenido, lo que determinarí´ìsua la utilidad para los experimentos, en el que se espera que 20 pasen a formar parte del dataset definitivo.Otro punt 

efinfio 20 a realizarse.rtfo disobre todoen a en su´ñon apor una seleccióde  oe50 rededor ogle Docs, easí  ´nviando cou historial completoin ello su . Este  Doehde la facu´,  base de t ,  ´ìalan descComo 

Avance
 y trabajo previoEl proyecto actualmente se encuentra avanzado en 3 àreva



V